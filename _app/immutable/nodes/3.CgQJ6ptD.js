import"../chunks/DsnmJJEf.js";import"../chunks/DbNsreHr.js";import{p as Q,f as q,t as F,a as J,b as X,d as e,s as i,n as r,r as a}from"../chunks/2ADFmShP.js";import{s as n}from"../chunks/B3h5ZDU-.js";import{i as Z}from"../chunks/D21C0wAS.js";import{r as o}from"../chunks/D-hN4oU3.js";var $=q('<main class="subcontainer"><div class="home-split-ver"><div class="card"><h1 class="h1">Who are we?</h1> <p class="lead">Our international team includes <strong>leading experts on the evaluation of gesture-generation models</strong>, as well as <strong>experienced model developers</strong> and <strong>research engineers</strong> with experience in deploying gesture-generation models. Together, we are developing the leaderboard and its associated tooling, and we will be responsible for managing and funding year-round crowdsourced human evaluations.</p> <p class="lead">Our cumulative experience covers <strong>all major aspects of gesture-generation research</strong>, including:</p> <ul class="bulleted"><li><strong>crowdsourced evaluation</strong>: e.g., organising the GENEA Challenges in 2020-2024 (the leading large-scale human evaluation efforts in gesture generation to date!)</li> <li><strong>data collection</strong>: e.g., TED Gesture dataset</li> <li><strong>model development</strong>: e.g., Gesticulator (ICMI 2020 Best paper), Gesture Generation from Trimodal Context (SIGGRAPH Asia 2020), StyleGestures (EUROGRAPHICS 2020 Honourable mention), Listen, Denoise, Action! (SIGGRAPH 2023), AQ-GT (ICMI 2023 Best paper)</li> <li><strong>visualisation tooling</strong>: e.g., Blender, Maya, and Unreal Engine development</li></ul></div> <div class="card"><h1 class="h1">Organizers</h1> <div class="image-grid"><div class="image-item"><img alt="Image 1 description"/> <div class="caption"><h3><a href="https://youngwoo-yoon.github.io/" rel="external nofollow noopener" target="_blank">Youngwoo Yoon</a></h3> <p>Principal Researcher</p> <p>ETRI, South Korea</p></div></div> <div class="image-item"><img alt="Image 2 description"/> <div class="caption"><h3><a href="https://svito-zar.github.io/" rel="external nofollow noopener" target="_blank">Taras Kucherenko</a></h3> <p>Research Scientist</p> <p>Electronic Arts - SEED, Sweden</p></div></div> <div class="image-item"><img alt="Image 3 description"/> <div class="caption"><h3><a href="https://people.kth.se/~ghe/" rel="external nofollow noopener" target="_blank">Gustav Eje Henter</a></h3> <p>Assistant Professor</p> <p>KTH Royal Institute of Technology</p> <p>Head of Research motorica.ai, Sweden</p></div></div> <div class="image-item"><img alt="Image 4 description"/> <div class="caption"><h3><a href="https://nagyrajmund.github.io/" rel="external nofollow noopener" target="_blank">Rajmund Nagy</a></h3> <p>Doctoral Student</p> <p>KTH Royal Institute of Technology</p> <p>Sweden</p></div></div> <div class="image-item"><img alt="Image 5 description"/> <div class="caption"><h3><a href="https://techfak.uni-bielefeld.de/~hvoss/" rel="external nofollow noopener" target="_blank">Hendric Vo√ü</a></h3> <p>Doctoral Student</p> <p>Bielefeld University, Germany</p></div></div> <div class="image-item"><img alt="Image 6 description"/> <div class="caption"><h3><a href="https://hmthanh.github.io/" rel="external nofollow noopener" target="_blank">Thanh Hoang-Minh</a></h3> <p>MSc Student</p> <p>VNUHCM - University of Science, Vietnam</p></div></div> <div class="image-item"><img alt="Image 7 description"/> <div class="caption"><h3><a href="https://www.teonikolov.com/" rel="external nofollow noopener" target="_blank">Teodor Nikolov</a></h3> <p>Research Engineer</p> <p>motorica.ai, Sweden</p></div></div> <div class="image-item"><img alt="Image 8 description"/> <div class="caption"><h3><a href="https://www.linkedin.com/in/mihailtsakov/" rel="external nofollow noopener" target="_blank">Mihail Tsakov</a></h3> <p>Unreal Engine Developer</p> <p>Liahim, Netherlands</p></div></div></div></div> <div class="card"><h1 class="h1">Scientific advisors</h1> <p>While the organising team handles day-to-day operations, we are fortunate to be advised in key strategic decisions and the leaderboard methodology by three leading experts of nonverbal communication, visual perception, human-agent interaction, and motion capture:</p> <div class="image-grid2"><div class="image-item"><img alt="Image 1 description"/> <div class="caption"><h3><a href="https://www.scss.tcd.ie/rachel.mcdonnell/" rel="external nofollow noopener" target="_blank">Rachel McDonnell</a></h3> <p>Trinity College Dublin, Ireland</p></div></div> <div class="image-item"><img alt="Image 2 description"/> <div class="caption"><h3><a href="https://www.cs.ucdavis.edu/~neff/" rel="external nofollow noopener" target="_blank">Michael Neff</a></h3> <p>University of California, Davis, USA</p></div></div> <div class="image-item"><img alt="Image 3 description"/> <div class="caption"><h3><a href="https://www.techfak.uni-bielefeld.de/~skopp/" rel="external nofollow noopener" target="_blank">Stefan Kopp</a></h3> <p>Bielefeld University, Germany</p></div></div></div></div></div></main>');function te(I,x){Q(x,!1),Z();var t=$(),f=e(t),s=i(e(f),2),w=i(e(s),2),l=e(w),S=e(l);r(2),a(l);var d=i(l,2),G=e(d);r(2),a(d);var g=i(d,2),T=e(g);r(2),a(g);var p=i(g,2),j=e(p);r(2),a(p);var c=i(p,2),z=e(c);r(2),a(c);var v=i(c,2),R=e(v);r(2),a(v);var h=i(v,2),E=e(h);r(2),a(h);var _=i(h,2),H=e(_);r(2),a(_),a(w),a(s);var b=i(s,2),y=i(e(b),4),m=e(y),A=e(m);r(2),a(m);var u=i(m,2),D=e(u);r(2),a(u);var k=i(u,2),M=e(k);r(2),a(k),a(y),a(b),a(f),a(t),F((U,C,N,B,K,P,O,V,L,W,Y)=>{n(S,"src",U),n(G,"src",C),n(T,"src",N),n(j,"src",B),n(z,"src",K),n(R,"src",P),n(E,"src",O),n(H,"src",V),n(A,"src",L),n(D,"src",W),n(M,"src",Y)},[()=>o("/organizers/youngwoo.jpg"),()=>o("/organizers/taras.jpg"),()=>o("/organizers/gustav.jpeg"),()=>o("/organizers/rajmund.png"),()=>o("/organizers/hendric.jpg"),()=>o("/organizers/thanh.png"),()=>o("/organizers/teodor.jpeg"),()=>o("/organizers/mihail.png"),()=>o("/organizers/rachel.jpg"),()=>o("/organizers/michael.jpg"),()=>o("/organizers/stefan.jpeg")]),J(I,t),X()}export{te as component};
