<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> GENEA Leaderboard </title> <meta name="author" content="GENEA Leaderboard "> <meta name="description" content="An overview of the leaderboard initiative"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/leaderboard/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/leaderboard/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/leaderboard/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/leaderboard/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://genea-workshop.github.io/leaderboard/"> <script src="/leaderboard/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/leaderboard/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/leaderboard/">Towards an online leaderboard for gesture generation <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Towards an online leaderboard for gesture generation</h1> <p class="post-meta"> Created on May 17, 2024 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </p> </header> <article class="post-content"> <div id="markdown-content"> <div style="text-align: center; margin-bottom: 2em;"> <img src="./assets/img/genea-logo.png" alt="The GENEA Leaderboard logo" width="100%"> </div> <blockquote> <p>To improve benchmarking of speech-driven gesture generation, we are developing the online GENEA Leaderboard. This is a cross between the previous <a href="https://svito-zar.github.io/GENEAchallenge2023/" rel="external nofollow noopener" target="_blank">GENEA Challenges in gesture generation</a> and recent leaderboards in NLP and computer vision, such as <a href="https://chat.lmsys.org/?leaderboard" rel="external nofollow noopener" target="_blank">Chatbot Arena</a> and <a href="https://crfm.stanford.edu/helm/heim/v1.0.0/#/" rel="external nofollow noopener" target="_blank">HEIM</a>.</p> </blockquote> <h2 id="our-goals">Our goals</h2> <ul> <li>Establish a <strong>living benchmark</strong> of gesture-generation models using <strong>human evaluation</strong> </li> <li>Ensure <strong>high reproducibility</strong> by releasing all collected model outputs, human ratings, and scripts for motion visualisation, conducting user-studies, and more</li> <li>Develop <strong>better objective metrics</strong> based on the collected human ratings</li> <li> <strong>Unify gesture-generation</strong> researchers from computer vision, computer graphics, machine learning, NLP, and HCI</li> <li>Evolve with the community</li> </ul> <h2 id="leaderboard-setup">Leaderboard setup</h2> <p>Gesture-generation models are currently scattered across different datasets, and it is often difficult to successfully retrain someone else’s model on new data.</p> <p>To populate the leaderboard, we are currently inviting authors of up to 15 recent gesture-generation models to participate in a large-scale evaluation. The organisers will conduct a comprehensive evaluation of the submitted systems, which will then be published on our website, alongside all collected outputs, ratings, and scripts necessary for reproducing the evaluation.</p> <p>After this initial evaluation is completed, the leaderboard will become open to public submissions, and will be continuously updated by the GENEA team.</p> <h3 id="dataset">Dataset</h3> <p>The leaderboard is going to use the <a href="https://pantomatrix.github.io/EMAGE/" rel="external nofollow noopener" target="_blank">BEAT-v2 dataset</a> in the SMPL-X format, without facial expressions. We think this data is the best candidate for an initial benchmark dataset for several reasons:</p> <ol> <li>It’s the largest public mocap dataset of gesturing (with 60 hours of data)</li> <li>High variety, with 8 emotions, 25 speakers, and 4 languages</li> <li>It includes semantic gesture annotations</li> <li>The SMPL-X format is compatible with many other datasets</li> <li>It also includes facial expressions (a possible future addition for the leaderboard)</li> </ol> <figure style="text-align: center; margin-bottom: 2em;"> <img src="https://pantomatrix.github.io/EMAGE/assets/video_t.gif" alt="Official BEAT dataset gif that shows several animated speaking avatars." width="90%"> <figcaption><i>Speaking BEAT dataset avatars.</i></figcaption> </figure> <p>Being a living leaderboard, the dataset used for benchmarking is expected to evolve in the future as newer datasets become available.</p> <h2 id="how-to-participate">How to participate</h2> <p>To participate in the evaluation, you will need to:</p> <ol> <li>Train your model on the <a href="https://pantomatrix.github.io/EMAGE/" rel="external nofollow noopener" target="_blank">BEAT-v2</a> dataset, with the official test set held out.</li> <li>Generate motion for the leaderboard’s test set (a superset of the BEAT-v2 test set; will be provided at a later time).</li> <li>Submit the generated motion to the leaderboard organisers, alongside your paper or brief technical report describing the details of your model. If submitting an already published model, you only need to document the adaptations you made for the new dataset.</li> </ol> <h2 id="evaluation-methodology">Evaluation methodology</h2> <p>We will recruit a large number of evaluators on a crowd-sourcing platform to conduct best-practises human evaluation on three aspects:</p> <ol> <li>Motion naturalness</li> <li>Motion appropriateness for the speech</li> <li>Emotional expression</li> </ol> <figure style="text-align: center; margin-bottom: 2em;"> <img src="./assets/img/user_study_interface.png" alt="Gif of the genea challenge 2023 visualizer." width="80%"> <figcaption><i>Evaluation interface for the user studies.</i></figcaption> </figure> <p>The human evaluation will use a standardised visualisation with a free and open-source mesh.</p> <p>For <strong>motion naturalness</strong>, we will use an ELO-based system with pairwise comparisons (Bradley-Terry), similar to <a href="https://lmsys.org/blog/2023-12-07-leaderboard/#transition-from-online-elo-rating-system-to-bradley-terry-model" rel="external nofollow noopener" target="_blank">Chatbot Arena</a>.</p> <p>To accurately quantify <strong>motion appropriateness</strong>, we will use a mismatching procedure based on the <a href="https://arxiv.org/abs/2308.12646" rel="external nofollow noopener" target="_blank">GENEA Challenges</a>.</p> <p>The leaderboard will also include all commonly used objective metrics and model properties such as size, memory usage, etc.</p> <h2 id="timeline">Timeline</h2> <p>Our current plan is to gather submissions for the first evaluation until the <strong>end of October</strong>, and to launch the leaderboard by the end of the year.</p> <h2 id="frequently-asked-questions">Frequently asked questions</h2> <ul> <li>How are the evaluations funded? <ul> <li>We currently have academic funding for running the leaderboard for a period of time. Having your system evaluated by the leaderboard will be free of charge. However, if there are a lot of systems submitted, we might not be able to evaluate all of them.</li> </ul> </li> <li>Why do we need a leaderboard? <ul> <li>Gesture generation research is currently fragmented across different datasets and evaluation protocols.</li> <li>Objective metrics are inconsistently applied, and their validity is not sufficiently established in the literature.</li> <li>At the same time, subjective evaluation methods often have low reproducibility, and their results are impossible to directly compare to each other.</li> <li>This leads to a situation where it is impossible to know what is the state of the art, or to know which method works better for which purpose when comparing two publications.</li> <li>The leaderboard is designed to directly counter these issues.</li> </ul> </li> </ul> <h2 id="organisers">Organisers</h2> <p>…</p> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/leaderboard/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/leaderboard/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/leaderboard/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/leaderboard/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/leaderboard/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/leaderboard/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/leaderboard/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>